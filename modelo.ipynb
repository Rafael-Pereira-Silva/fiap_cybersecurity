{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Caminho para o arquivo CSV\n",
    "file_path = '/content/dataset.csv'\n",
    "\n",
    "# Carregar o conjunto de dados com o separador correto\n",
    "data = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Visualizar as primeiras linhas do conjunto de dados para verificar se foi carregado corretamente\n",
    "data.head(5)\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "# Remoção de valores duplicados\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Tratamento de valores ausentes\n",
    "data.dropna(subset=['Organização', 'Nome'], inplace=True)  # Remove linhas onde 'Organização' ou 'Nome' estão ausentes\n",
    "\n",
    "\n",
    "# Visualizar as primeiras linhas após a limpeza\n",
    "print(data.head())\n",
    "\n",
    "# Salvar os dados limpos em um novo arquivo CSV\n",
    "data.to_csv('dados_limpos.csv', index=False)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carregamento do conjunto de dados limpo\n",
    "file_path_limpo = '/content/dados_limpos.csv'\n",
    "data_limpo = pd.read_csv(file_path_limpo)\n",
    "\n",
    "# Resumo estatístico\n",
    "print(data_limpo.describe())\n",
    "\n",
    "# Histogramas para variáveis numéricas\n",
    "data_limpo.hist(figsize=(10, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de contagem para variáveis categóricas ('Organização' e 'Tags')\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.countplot(data=data_limpo, x='Organização')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data_limpo, x='Tags')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Matriz de correlação (se houver variáveis numéricas)\n",
    "numeric_data = data_limpo.select_dtypes(include='number')\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.show()\n",
    "\n",
    "# Divisão dos dados em features (X) e target (y)\n",
    "X = data_limpo.drop(columns=['Quantidade Seguidores'])\n",
    "y = data_limpo['Quantidade Recursos']\n",
    "\n",
    "\n",
    "# Tratamento das variáveis categóricas usando get_dummies\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Divisão em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definição do modelo (exemplo: regressão linear)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Definição dos hiperparâmetros para tuning\n",
    "parameters = {'fit_intercept': [True, False]}\n",
    "\n",
    "# Aplicação do GridSearchCV para tuning de hiperparâmetros\n",
    "grid_search = GridSearchCV(model, parameters, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhores hiperparâmetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Melhores Hiperparâmetros Encontrados:\", best_params)\n",
    "\n",
    "# Treinamento do modelo com os melhores hiperparâmetros\n",
    "best_model = LinearRegression(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predição no conjunto de teste\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Avaliação do modelo usando métricas (exemplo: MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Gerar dados sintéticos para treinar um modelo (substitua com seus próprios dados)\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)\n",
    "\n",
    "# Treinar um modelo (usando regressão linear como exemplo)\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Salvar o modelo treinado em um arquivo\n",
    "joblib.dump(model, 'modelo.pkl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
